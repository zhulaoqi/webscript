"""
å·¥å…·å‡½æ•°
"""
import os
import time
import random
import requests
import zipfile
from pathlib import Path
from typing import Dict, List, Optional
from urllib.parse import urlparse
import json
from tqdm import tqdm
import boto3
from botocore.exceptions import ClientError
from config import DOWNLOAD_CONFIG, USER_AGENTS, AWS_S3_CONFIG


class S3Uploader:
    """S3ä¸Šä¼ å·¥å…·ç±»"""
    
    def __init__(self):
        """åˆå§‹åŒ–S3å®¢æˆ·ç«¯"""
        self.s3_client = boto3.client(
            's3',
            aws_access_key_id=AWS_S3_CONFIG['access_key_id'],
            aws_secret_access_key=AWS_S3_CONFIG['secret_access_key'],
            region_name=AWS_S3_CONFIG['region']
        )
        self.bucket_name = AWS_S3_CONFIG['bucket_name']
        self.cdn_prefix = AWS_S3_CONFIG['url_prefix']
    
    def upload_file(self, local_path: str, s3_key: str) -> Optional[str]:
        """
        ä¸Šä¼ æ–‡ä»¶åˆ°S3
        
        Args:
            local_path: æœ¬åœ°æ–‡ä»¶è·¯å¾„
            s3_key: S3å¯¹è±¡é”®å
            
        Returns:
            CDN URLæˆ–None
        """
        try:
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(local_path):
                print(f"âš ï¸  æœ¬åœ°æ–‡ä»¶ä¸å­˜åœ¨: {local_path}")
                return None
            
            # ç¡®å®šContent-Type
            content_type = self._get_content_type(local_path)
            
            print(f"    ğŸ“¤ ä¸Šä¼ ä¸­: {os.path.basename(local_path)} -> S3")
            
            # ä¸Šä¼ æ–‡ä»¶ï¼ˆä¸ä½¿ç”¨ACLï¼Œå­˜å‚¨æ¡¶å·²é…ç½®ä¸ºå…¬å¼€è®¿é—®ï¼‰
            self.s3_client.upload_file(
                local_path,
                self.bucket_name,
                s3_key,
                ExtraArgs={
                    'ContentType': content_type
                }
            )
            
            # è¿”å›CDN URL
            cdn_url = f"{self.cdn_prefix}{s3_key}"
            print(f"    âœ… S3æˆåŠŸ: {cdn_url}")
            return cdn_url
            
        except ClientError as e:
            print(f"    âŒ S3ä¸Šä¼ å¤±è´¥: {e}")
            return None
        except Exception as e:
            print(f"    âŒ ä¸Šä¼ é”™è¯¯: {e}")
            return None
    
    @staticmethod
    def _get_content_type(file_path: str) -> str:
        """æ ¹æ®æ–‡ä»¶æ‰©å±•åè·å–Content-Type"""
        ext = os.path.splitext(file_path)[1].lower()
        content_types = {
            '.mp4': 'video/mp4',
            '.mov': 'video/quicktime',
            '.avi': 'video/x-msvideo',
            '.jpg': 'image/jpeg',
            '.jpeg': 'image/jpeg',
            '.png': 'image/png',
            '.gif': 'image/gif',
            '.webp': 'image/webp',
        }
        return content_types.get(ext, 'application/octet-stream')


class DownloadUtils:
    """ä¸‹è½½å·¥å…·ç±»"""
    
    @staticmethod
    def get_random_user_agent() -> str:
        """è·å–éšæœºUser-Agent"""
        return random.choice(USER_AGENTS)
    
    @staticmethod
    def random_delay():
        """éšæœºå»¶è¿Ÿ"""
        delay = random.uniform(
            DOWNLOAD_CONFIG['delay_min'], 
            DOWNLOAD_CONFIG['delay_max']
        )
        time.sleep(delay)
    
    @staticmethod
    def download_file(url: str, save_path: str, proxies: Optional[Dict] = None, referer: str = None) -> bool:
        """
        ä¸‹è½½æ–‡ä»¶ï¼ˆæ”¯æŒé˜²ç›—é“¾çªç ´ï¼‰
        
        Args:
            url: æ–‡ä»¶URL
            save_path: ä¿å­˜è·¯å¾„
            proxies: ä»£ç†é…ç½®
            referer: æ¥æºé¡µé¢ï¼ˆç”¨äºçªç ´é˜²ç›—é“¾ï¼‰
            
        Returns:
            æ˜¯å¦ä¸‹è½½æˆåŠŸ
        """
        # è·³è¿‡blobå’Œdata URLs
        if url.startswith('blob:') or url.startswith('data:'):
            return False
        
        # è·³è¿‡ç”¨æˆ·å¤´åƒã€å›¾æ ‡ç­‰éç´ æå†…å®¹
        skip_patterns = [
            'profile-image', 'avatar', 'user-avatar', 'user_avatar',
            'favicon', 'logo', 'icon', 'thumbnail_placeholder',
            '/users/', '/user/', '/profile/', '/creator/',
        ]
        url_lower = url.lower()
        for pattern in skip_patterns:
            if pattern in url_lower:
                return False
        
        max_retries = DOWNLOAD_CONFIG['max_retries']
        timeout = 60  # å¢åŠ è¶…æ—¶æ—¶é—´åˆ°60ç§’
        
        # æ ¹æ®URLæ¨æ–­æ¥æºç½‘ç«™
        if not referer:
            from urllib.parse import urlparse
            parsed = urlparse(url)
            referer = f"{parsed.scheme}://{parsed.netloc}/"
        
        for attempt in range(max_retries):
            try:
                # å¢å¼ºè¯·æ±‚å¤´ï¼Œæ¨¡æ‹ŸçœŸå®æµè§ˆå™¨
                headers = {
                    'User-Agent': DownloadUtils.get_random_user_agent(),
                    'Referer': referer,  # ä½¿ç”¨æ­£ç¡®çš„æ¥æºé¡µé¢
                    'Accept': '*/*',
                    'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
                    'Accept-Encoding': 'gzip, deflate, br',
                    'Connection': 'keep-alive',
                    'Sec-Fetch-Dest': 'video' if '.mp4' in url or '.mov' in url else 'image',
                    'Sec-Fetch-Mode': 'no-cors',
                    'Sec-Fetch-Site': 'same-origin',
                }
                
                # åŠ¨æ€è¶…æ—¶ï¼šè¿æ¥è¶…æ—¶15ç§’ï¼Œè¯»å–è¶…æ—¶60ç§’
                response = requests.get(
                    url, 
                    headers=headers, 
                    proxies=proxies,
                    timeout=(15, 60),  # (connect timeout, read timeout)
                    stream=True,
                    allow_redirects=True  # å…è®¸é‡å®šå‘
                )
                response.raise_for_status()
                
                # æ£€æŸ¥Content-Typeï¼Œç¡®ä¿ä¸æ˜¯HTMLé”™è¯¯é¡µ
                content_type = response.headers.get('content-type', '').lower()
                if 'text/html' in content_type:
                    return False
                
                # ç¡®ä¿ç›®å½•å­˜åœ¨
                os.makedirs(os.path.dirname(save_path), exist_ok=True)
                
                # ä¸‹è½½æ–‡ä»¶
                total_size = int(response.headers.get('content-length', 0))
                downloaded_size = 0
                
                with open(save_path, 'wb') as f:
                    if total_size == 0:
                        content = response.content
                        f.write(content)
                        downloaded_size = len(content)
                    else:
                        for chunk in response.iter_content(chunk_size=8192):
                            if chunk:
                                f.write(chunk)
                                downloaded_size += len(chunk)
                
                # éªŒè¯ä¸‹è½½å®Œæ•´æ€§
                if total_size > 0 and downloaded_size < total_size * 0.9:
                    if attempt < max_retries - 1:
                        time.sleep(2 ** attempt)
                        continue
                    return False
                
                # æ£€æŸ¥æ–‡ä»¶å¤§å°ï¼ˆè‡³å°‘1KBï¼Œé¿å…ä¸‹è½½åˆ°é”™è¯¯é¡µé¢ï¼‰
                if downloaded_size < 1024:
                    return False
                
                return True
                
            except requests.exceptions.Timeout as e:
                # è¶…æ—¶é”™è¯¯ï¼Œé™é»˜é‡è¯•
                if attempt < max_retries - 1:
                    time.sleep(3)  # ç­‰å¾…3ç§’åé‡è¯•
                    continue
                return False
            except requests.exceptions.ConnectionError as e:
                # è¿æ¥é”™è¯¯ï¼Œé™é»˜é‡è¯•
                if attempt < max_retries - 1:
                    time.sleep(3)
                    continue
                return False
            except Exception as e:
                # å…¶ä»–é”™è¯¯
                if attempt < max_retries - 1:
                    time.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿
                    continue
                return False
                    
        return False
    
    @staticmethod
    def get_file_extension(url: str) -> str:
        """ä»URLè·å–æ–‡ä»¶æ‰©å±•å"""
        parsed = urlparse(url)
        path = parsed.path
        ext = os.path.splitext(path)[1]
        if not ext:
            # å°è¯•ä»æŸ¥è¯¢å‚æ•°è·å–
            if 'format=' in url:
                ext = '.' + url.split('format=')[1].split('&')[0]
            else:
                ext = '.mp4'  # é»˜è®¤è§†é¢‘æ ¼å¼
        return ext


class DataManager:
    """æ•°æ®ç®¡ç†ç±»"""
    
    def __init__(self, output_dir: str, use_s3: bool = True):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # åˆ›å»ºå­ç›®å½•
        self.text2video_dir = self.output_dir / 'text2video'
        self.image2video_dir = self.output_dir / 'image2video'
        self.text2video_dir.mkdir(exist_ok=True)
        self.image2video_dir.mkdir(exist_ok=True)
        
        # Excel æ•°æ®å­˜å‚¨ï¼ˆå†…å­˜ä¸­ç»´æŠ¤ï¼‰
        self.excel_data: Dict[str, List[List]] = {}  # {site_name: [[row1], [row2], ...]}
        
        # S3ä¸Šä¼ å™¨
        self.use_s3 = use_s3
        if use_s3:
            self.s3_uploader = S3Uploader()
            print("âœ“ S3ä¸Šä¼ å·²å¯ç”¨")
    
    def upload_to_s3(self, local_path: str, category: str, filename: str) -> Optional[str]:
        """
        ä¸Šä¼ æ–‡ä»¶åˆ°S3å¹¶è¿”å›URL
        
        Args:
            local_path: æœ¬åœ°æ–‡ä»¶è·¯å¾„
            category: åˆ†ç±»ï¼ˆç”¨äºS3è·¯å¾„ï¼‰
            filename: æ–‡ä»¶å
            
        Returns:
            S3 CDN URL
        """
        if not self.use_s3 or not local_path or not os.path.exists(local_path):
            return None
        
        # ç”ŸæˆS3é”®å: video-materials/æ–‡ä»¶å (ä¸å†åŒ…å«ç½‘ç«™åˆ†ç±»)
        if category:
            s3_key = f"video-materials/{category}/{filename}"
        else:
            s3_key = f"video-materials/{filename}"
        
        # ä¸Šä¼ å¹¶è·å–URL
        cdn_url = self.s3_uploader.upload_file(local_path, s3_key)
        
        return cdn_url
    
    
    def append_to_txt(self, work_url: str, site_name: str, source_url: str = '', prompt: str = '', cover_url: str = ''):
        """
        å®æ—¶è¿½åŠ æ•°æ®åˆ° Excel æ•°æ®ï¼ˆå†…å­˜ä¸­ï¼‰
        
        Args:
            work_url: ä½œå“URLï¼ˆè§†é¢‘æˆ–å›¾ç‰‡ï¼‰
            site_name: ç½‘ç«™åç§°
            source_url: åŸå›¾URLï¼ˆå›¾ç”Ÿè§†é¢‘/å›¾ç”Ÿå›¾çš„è¾“å…¥å›¾ï¼‰
            prompt: æç¤ºè¯
            cover_url: ç¼©ç•¥å›¾URLï¼ˆè§†é¢‘å°é¢ï¼‰
        """
        try:
            # æ¸…ç†æç¤ºè¯ï¼ˆå»æ‰æ¢è¡Œç¬¦ï¼Œé™åˆ¶é•¿åº¦ï¼‰
            if prompt:
                prompt = prompt.replace('\n', ' ').replace('\r', ' ').replace('\t', ' ')
                # å»é™¤å¤šä½™ç©ºæ ¼
                prompt = ' '.join(prompt.split())
                # é™åˆ¶é•¿åº¦
                if len(prompt) > 500:
                    prompt = prompt[:500]
            
            # ç½‘ç«™æ ‡è¯†
            site_normalized = site_name.lower().replace(' ', '_').replace('.', '_')
            
            # æ·»åŠ åˆ° Excel æ•°æ®ï¼ˆå†…å­˜ä¸­ï¼‰
            if site_normalized not in self.excel_data:
                self.excel_data[site_normalized] = []
            
            self.excel_data[site_normalized].append([
                work_url,
                source_url or 'æ— åŸå›¾',
                prompt or 'æ— æç¤ºè¯',
                cover_url or 'æ— ç¼©ç•¥å›¾'
            ])
            
            # åŒæ—¶æ·»åŠ åˆ°æ€»æ•°æ®
            if 'all_materials' not in self.excel_data:
                self.excel_data['all_materials'] = []
            
            self.excel_data['all_materials'].append([
                work_url,
                source_url or 'æ— åŸå›¾',
                prompt or 'æ— æç¤ºè¯',
                cover_url or 'æ— ç¼©ç•¥å›¾'
            ])
                
        except Exception as e:
            print(f"  âš ï¸  å†™å…¥æ•°æ®å¤±è´¥: {e}")
    
    def save_excel(self):
        """
        ä¿å­˜ Excel æ–‡ä»¶ï¼ˆä»å†…å­˜ä¸­çš„æ•°æ®ï¼‰
        æ¯ä¸ªç½‘ç«™ä¸€ä¸ª Excel æ–‡ä»¶ï¼ŒåŠ ä¸€ä¸ªæ€»çš„ all_materials.xlsx
        æ ¼å¼ï¼šä½œå“URL | åŸå›¾URL | æç¤ºè¯ | ç¼©ç•¥å›¾URL
        """
        try:
            if not self.excel_data:
                print("  â„¹ï¸  æ²¡æœ‰æ•°æ®éœ€è¦ä¿å­˜åˆ° Excel")
                return
            
            print(f"\nğŸ“Š ç”Ÿæˆ Excel æ–‡ä»¶...")
            
            for site_name, rows in self.excel_data.items():
                if not rows:
                    continue
                
                # åˆ›å»ºå·¥ä½œç°¿
                wb = Workbook()
                ws = wb.active
                ws.title = "ç´ ææ•°æ®"
                
                # è®¾ç½®è¡¨å¤´
                headers = ["ä½œå“URL", "åŸå›¾URL", "æç¤ºè¯", "ç¼©ç•¥å›¾URL"]
                ws.append(headers)
                
                # è®¾ç½®è¡¨å¤´æ ·å¼
                for cell in ws[1]:
                    cell.font = Font(bold=True, size=12)
                    cell.alignment = Alignment(horizontal='center', vertical='center')
                
                # æ·»åŠ æ•°æ®
                for row in rows:
                    ws.append(row)
                
                # è‡ªåŠ¨è°ƒæ•´åˆ—å®½
                for column in ws.columns:
                    max_length = 0
                    column_letter = column[0].column_letter
                    for cell in column:
                        try:
                            if len(str(cell.value)) > max_length:
                                max_length = len(str(cell.value))
                        except:
                            pass
                    adjusted_width = min(max_length + 2, 100)  # æœ€å¤§100å­—ç¬¦å®½åº¦
                    ws.column_dimensions[column_letter].width = adjusted_width
                
                # ä¿å­˜æ–‡ä»¶
                excel_path = self.output_dir.parent / f'{site_name}.xlsx'
                wb.save(excel_path)
                print(f"  âœ… {site_name}.xlsx ({len(rows)} æ¡)")
            
            print(f"ğŸ“Š Excel æ–‡ä»¶ç”Ÿæˆå®Œæˆï¼")
            
        except Exception as e:
            print(f"  âš ï¸  ç”Ÿæˆ Excel å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    
    
    def get_summary(self) -> Dict:
        """è·å–æ•°æ®æ‘˜è¦ï¼ˆåŸºäº Excel æ•°æ®ï¼‰"""
        total_count = sum(len(rows) for rows in self.excel_data.values() if rows)
        # å‡å»é‡å¤çš„ all_materials è®¡æ•°
        if 'all_materials' in self.excel_data:
            total_count = len(self.excel_data['all_materials'])
        
        return {
            'text2video_count': 0,  # å·²ä¸å†å•ç‹¬ç»Ÿè®¡
            'image2video_count': 0,  # å·²ä¸å†å•ç‹¬ç»Ÿè®¡
            'total_count': total_count
        }


def setup_proxy(proxy_config: Dict) -> Optional[Dict]:
    """
    è®¾ç½®ä»£ç†
    
    Args:
        proxy_config: ä»£ç†é…ç½®
        
    Returns:
        requestsä»£ç†å­—å…¸
    """
    if not proxy_config.get('host'):
        return None
    
    if proxy_config.get('user') and proxy_config.get('password'):
        proxy_url = f"http://{proxy_config['user']}:{proxy_config['password']}@{proxy_config['host']}"
        if proxy_config.get('port'):
            proxy_url += f":{proxy_config['port']}"
    else:
        proxy_url = f"http://{proxy_config['host']}"
        if proxy_config.get('port'):
            proxy_url += f":{proxy_config['port']}"
    
    return {
        'http': proxy_url,
        'https': proxy_url
    }

