"""
Â∑•ÂÖ∑ÂáΩÊï∞
"""
import os
import time
import random
import requests
import zipfile
from pathlib import Path
from typing import Dict, List, Optional
from urllib.parse import urlparse
import json
from tqdm import tqdm
import boto3
from botocore.exceptions import ClientError
from config import DOWNLOAD_CONFIG, USER_AGENTS, AWS_S3_CONFIG


class S3Uploader:
    """S3‰∏ä‰º†Â∑•ÂÖ∑Á±ª"""
    
    def __init__(self):
        """ÂàùÂßãÂåñS3ÂÆ¢Êà∑Á´Ø"""
        self.s3_client = boto3.client(
            's3',
            aws_access_key_id=AWS_S3_CONFIG['access_key_id'],
            aws_secret_access_key=AWS_S3_CONFIG['secret_access_key'],
            region_name=AWS_S3_CONFIG['region']
        )
        self.bucket_name = AWS_S3_CONFIG['bucket_name']
        self.cdn_prefix = AWS_S3_CONFIG['url_prefix']
    
    def upload_file(self, local_path: str, s3_key: str) -> Optional[str]:
        """
        ‰∏ä‰º†Êñá‰ª∂Âà∞S3
        
        Args:
            local_path: Êú¨Âú∞Êñá‰ª∂Ë∑ØÂæÑ
            s3_key: S3ÂØπË±°ÈîÆÂêç
            
        Returns:
            CDN URLÊàñNone
        """
        try:
            # Ê£ÄÊü•Êñá‰ª∂ÊòØÂê¶Â≠òÂú®
            if not os.path.exists(local_path):
                print(f"‚ö†Ô∏è  Êú¨Âú∞Êñá‰ª∂‰∏çÂ≠òÂú®: {local_path}")
                return None
            
            # Á°ÆÂÆöContent-Type
            content_type = self._get_content_type(local_path)
            
            print(f"    üì§ ‰∏ä‰º†‰∏≠: {os.path.basename(local_path)} -> S3")
            
            # ‰∏ä‰º†Êñá‰ª∂Ôºà‰∏ç‰ΩøÁî®ACLÔºåÂ≠òÂÇ®Ê°∂Â∑≤ÈÖçÁΩÆ‰∏∫ÂÖ¨ÂºÄËÆøÈóÆÔºâ
            self.s3_client.upload_file(
                local_path,
                self.bucket_name,
                s3_key,
                ExtraArgs={
                    'ContentType': content_type
                }
            )
            
            # ËøîÂõûCDN URL
            cdn_url = f"{self.cdn_prefix}{s3_key}"
            print(f"    ‚úÖ S3ÊàêÂäü: {cdn_url}")
            return cdn_url
            
        except ClientError as e:
            print(f"    ‚ùå S3‰∏ä‰º†Â§±Ë¥•: {e}")
            return None
        except Exception as e:
            print(f"    ‚ùå ‰∏ä‰º†ÈîôËØØ: {e}")
            return None
    
    @staticmethod
    def _get_content_type(file_path: str) -> str:
        """Ê†πÊçÆÊñá‰ª∂Êâ©Â±ïÂêçËé∑ÂèñContent-Type"""
        ext = os.path.splitext(file_path)[1].lower()
        content_types = {
            '.mp4': 'video/mp4',
            '.mov': 'video/quicktime',
            '.avi': 'video/x-msvideo',
            '.jpg': 'image/jpeg',
            '.jpeg': 'image/jpeg',
            '.png': 'image/png',
            '.gif': 'image/gif',
            '.webp': 'image/webp',
        }
        return content_types.get(ext, 'application/octet-stream')


class DownloadUtils:
    """‰∏ãËΩΩÂ∑•ÂÖ∑Á±ª"""
    
    @staticmethod
    def get_random_user_agent() -> str:
        """Ëé∑ÂèñÈöèÊú∫User-Agent"""
        return random.choice(USER_AGENTS)
    
    @staticmethod
    def random_delay():
        """ÈöèÊú∫Âª∂Ëøü"""
        delay = random.uniform(
            DOWNLOAD_CONFIG['delay_min'], 
            DOWNLOAD_CONFIG['delay_max']
        )
        time.sleep(delay)
    
    @staticmethod
    def download_file(url: str, save_path: str, proxies: Optional[Dict] = None, referer: str = None) -> bool:
        """
        ‰∏ãËΩΩÊñá‰ª∂ÔºàÊîØÊåÅÈò≤ÁõóÈìæÁ™ÅÁ†¥Ôºâ
        
        Args:
            url: Êñá‰ª∂URL
            save_path: ‰øùÂ≠òË∑ØÂæÑ
            proxies: ‰ª£ÁêÜÈÖçÁΩÆ
            referer: Êù•Ê∫êÈ°µÈù¢ÔºàÁî®‰∫éÁ™ÅÁ†¥Èò≤ÁõóÈìæÔºâ
            
        Returns:
            ÊòØÂê¶‰∏ãËΩΩÊàêÂäü
        """
        # Ë∑≥ËøáblobÂíådata URLs
        if url.startswith('blob:') or url.startswith('data:'):
            return False
        
        # Ë∑≥ËøáÁî®Êà∑Â§¥ÂÉè„ÄÅÂõæÊ†áÁ≠âÈùûÁ¥†ÊùêÂÜÖÂÆπ
        skip_patterns = [
            'profile-image', 'avatar', 'user-avatar', 'user_avatar',
            'favicon', 'logo', 'icon', 'thumbnail_placeholder',
            '/users/', '/user/', '/profile/', '/creator/',
        ]
        url_lower = url.lower()
        for pattern in skip_patterns:
            if pattern in url_lower:
                return False
        
        max_retries = DOWNLOAD_CONFIG['max_retries']
        timeout = 60  # Â¢ûÂä†Ë∂ÖÊó∂Êó∂Èó¥Âà∞60Áßí
        
        # Ê†πÊçÆURLÊé®Êñ≠Êù•Ê∫êÁΩëÁ´ô
        if not referer:
            from urllib.parse import urlparse
            parsed = urlparse(url)
            referer = f"{parsed.scheme}://{parsed.netloc}/"
        
        for attempt in range(max_retries):
            try:
                # Â¢ûÂº∫ËØ∑Ê±ÇÂ§¥ÔºåÊ®°ÊãüÁúüÂÆûÊµèËßàÂô®
                headers = {
                    'User-Agent': DownloadUtils.get_random_user_agent(),
                    'Referer': referer,  # ‰ΩøÁî®Ê≠£Á°ÆÁöÑÊù•Ê∫êÈ°µÈù¢
                    'Accept': '*/*',
                    'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
                    'Accept-Encoding': 'gzip, deflate, br',
                    'Connection': 'keep-alive',
                    'Sec-Fetch-Dest': 'video' if '.mp4' in url or '.mov' in url else 'image',
                    'Sec-Fetch-Mode': 'no-cors',
                    'Sec-Fetch-Site': 'same-origin',
                }
                
                # Âä®ÊÄÅË∂ÖÊó∂ÔºöËøûÊé•Ë∂ÖÊó∂15ÁßíÔºåËØªÂèñË∂ÖÊó∂60Áßí
                response = requests.get(
                    url, 
                    headers=headers, 
                    proxies=proxies,
                    timeout=(15, 60),  # (connect timeout, read timeout)
                    stream=True,
                    allow_redirects=True  # ÂÖÅËÆ∏ÈáçÂÆöÂêë
                )
                response.raise_for_status()
                
                # Ê£ÄÊü•Content-TypeÔºåÁ°Æ‰øù‰∏çÊòØHTMLÈîôËØØÈ°µ
                content_type = response.headers.get('content-type', '').lower()
                if 'text/html' in content_type:
                    return False
                
                # Á°Æ‰øùÁõÆÂΩïÂ≠òÂú®
                os.makedirs(os.path.dirname(save_path), exist_ok=True)
                
                # ‰∏ãËΩΩÊñá‰ª∂
                total_size = int(response.headers.get('content-length', 0))
                downloaded_size = 0
                
                with open(save_path, 'wb') as f:
                    if total_size == 0:
                        content = response.content
                        f.write(content)
                        downloaded_size = len(content)
                    else:
                        for chunk in response.iter_content(chunk_size=8192):
                            if chunk:
                                f.write(chunk)
                                downloaded_size += len(chunk)
                
                # È™åËØÅ‰∏ãËΩΩÂÆåÊï¥ÊÄß
                if total_size > 0 and downloaded_size < total_size * 0.9:
                    if attempt < max_retries - 1:
                        time.sleep(2 ** attempt)
                        continue
                    return False
                
                # Ê£ÄÊü•Êñá‰ª∂Â§ßÂ∞èÔºàËá≥Â∞ë1KBÔºåÈÅøÂÖç‰∏ãËΩΩÂà∞ÈîôËØØÈ°µÈù¢Ôºâ
                if downloaded_size < 1024:
                    return False
                
                return True
                
            except requests.exceptions.Timeout as e:
                # Ë∂ÖÊó∂ÈîôËØØÔºåÈùôÈªòÈáçËØï
                if attempt < max_retries - 1:
                    time.sleep(3)  # Á≠âÂæÖ3ÁßíÂêéÈáçËØï
                    continue
                return False
            except requests.exceptions.ConnectionError as e:
                # ËøûÊé•ÈîôËØØÔºåÈùôÈªòÈáçËØï
                if attempt < max_retries - 1:
                    time.sleep(3)
                    continue
                return False
            except Exception as e:
                # ÂÖ∂‰ªñÈîôËØØ
                if attempt < max_retries - 1:
                    time.sleep(2 ** attempt)  # ÊåáÊï∞ÈÄÄÈÅø
                    continue
                return False
                    
        return False
    
    @staticmethod
    def get_file_extension(url: str) -> str:
        """‰ªéURLËé∑ÂèñÊñá‰ª∂Êâ©Â±ïÂêç"""
        parsed = urlparse(url)
        path = parsed.path
        ext = os.path.splitext(path)[1]
        if not ext:
            # Â∞ùËØï‰ªéÊü•ËØ¢ÂèÇÊï∞Ëé∑Âèñ
            if 'format=' in url:
                ext = '.' + url.split('format=')[1].split('&')[0]
            else:
                ext = '.mp4'  # ÈªòËÆ§ËßÜÈ¢ëÊ†ºÂºè
        return ext


class DataManager:
    """Êï∞ÊçÆÁÆ°ÁêÜÁ±ª"""
    
    def __init__(self, output_dir: str, use_s3: bool = True):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # ÂàõÂª∫Â≠êÁõÆÂΩï
        self.text2video_dir = self.output_dir / 'text2video'
        self.image2video_dir = self.output_dir / 'image2video'
        self.text2video_dir.mkdir(exist_ok=True)
        self.image2video_dir.mkdir(exist_ok=True)
        
        # Excel Êï∞ÊçÆÂ≠òÂÇ®ÔºàÂÜÖÂ≠ò‰∏≠Áª¥Êä§Ôºâ
        self.excel_data: Dict[str, List[List]] = {}  # {site_name: [[row1], [row2], ...]}
        
        # S3‰∏ä‰º†Âô®
        self.use_s3 = use_s3
        if use_s3:
            self.s3_uploader = S3Uploader()
            print("‚úì S3‰∏ä‰º†Â∑≤ÂêØÁî®")
    
    def upload_to_s3(self, local_path: str, category: str, filename: str) -> Optional[str]:
        """
        ‰∏ä‰º†Êñá‰ª∂Âà∞S3Âπ∂ËøîÂõûURL
        
        Args:
            local_path: Êú¨Âú∞Êñá‰ª∂Ë∑ØÂæÑ
            category: ÂàÜÁ±ªÔºàÁî®‰∫éS3Ë∑ØÂæÑÔºâ
            filename: Êñá‰ª∂Âêç
            
        Returns:
            S3 CDN URL
        """
        if not self.use_s3 or not local_path or not os.path.exists(local_path):
            return None
        
        # ÁîüÊàêS3ÈîÆÂêç: video-materials/Êñá‰ª∂Âêç (‰∏çÂÜçÂåÖÂê´ÁΩëÁ´ôÂàÜÁ±ª)
        if category:
            s3_key = f"video-materials/{category}/{filename}"
        else:
            s3_key = f"video-materials/{filename}"
        
        # ‰∏ä‰º†Âπ∂Ëé∑ÂèñURL
        cdn_url = self.s3_uploader.upload_file(local_path, s3_key)
        
        return cdn_url
    
    
    def append_to_txt(self, work_url: str, site_name: str, source_url: str = '', prompt: str = '', cover_url: str = ''):
        """
        ÂÆûÊó∂ËøΩÂä†Êï∞ÊçÆÂà∞ Excel Êï∞ÊçÆÔºàÂÜÖÂ≠ò‰∏≠Ôºâ
        
        Args:
            work_url: ‰ΩúÂìÅURLÔºàËßÜÈ¢ëÊàñÂõæÁâáÔºâ
            site_name: ÁΩëÁ´ôÂêçÁß∞
            source_url: ÂéüÂõæURLÔºàÂõæÁîüËßÜÈ¢ë/ÂõæÁîüÂõæÁöÑËæìÂÖ•ÂõæÔºâ
            prompt: ÊèêÁ§∫ËØç
            cover_url: Áº©Áï•ÂõæURLÔºàËßÜÈ¢ëÂ∞ÅÈù¢Ôºâ
        """
        try:
            # Ê∏ÖÁêÜÊèêÁ§∫ËØçÔºàÂéªÊéâÊç¢Ë°åÁ¨¶ÔºåÈôêÂà∂ÈïøÂ∫¶Ôºâ
            if prompt:
                prompt = prompt.replace('\n', ' ').replace('\r', ' ').replace('\t', ' ')
                # ÂéªÈô§Â§ö‰ΩôÁ©∫Ê†º
                prompt = ' '.join(prompt.split())
                # ÈôêÂà∂ÈïøÂ∫¶
                if len(prompt) > 500:
                    prompt = prompt[:500]
            
            # ÁΩëÁ´ôÊ†áËØÜ
            site_normalized = site_name.lower().replace(' ', '_').replace('.', '_')
            
            # Ê∑ªÂä†Âà∞ Excel Êï∞ÊçÆÔºàÂÜÖÂ≠ò‰∏≠Ôºâ
            if site_normalized not in self.excel_data:
                self.excel_data[site_normalized] = []
            
            self.excel_data[site_normalized].append([
                work_url,
                source_url or 'Êó†ÂéüÂõæ',
                prompt or 'Êó†ÊèêÁ§∫ËØç',
                cover_url or 'Êó†Áº©Áï•Âõæ'
            ])
            
            # ÂêåÊó∂Ê∑ªÂä†Âà∞ÊÄªÊï∞ÊçÆ
            if 'all_materials' not in self.excel_data:
                self.excel_data['all_materials'] = []
            
            self.excel_data['all_materials'].append([
                work_url,
                source_url or 'Êó†ÂéüÂõæ',
                prompt or 'Êó†ÊèêÁ§∫ËØç',
                cover_url or 'Êó†Áº©Áï•Âõæ'
            ])
                
        except Exception as e:
            print(f"  ‚ö†Ô∏è  ÂÜôÂÖ•Êï∞ÊçÆÂ§±Ë¥•: {e}")
    
    def save_excel(self):
        """
        ‰øùÂ≠ò Excel Êñá‰ª∂Ôºà‰ªéÂÜÖÂ≠ò‰∏≠ÁöÑÊï∞ÊçÆÔºâ
        ÊØè‰∏™ÁΩëÁ´ô‰∏Ä‰∏™ Excel Êñá‰ª∂ÔºåÂä†‰∏Ä‰∏™ÊÄªÁöÑ all_materials.xlsx
        Ê†ºÂºèÔºö‰ΩúÂìÅURL | ÂéüÂõæURL | ÊèêÁ§∫ËØç | Áº©Áï•ÂõæURL
        """
        try:
            if not self.excel_data:
                print("  ‚ÑπÔ∏è  Ê≤°ÊúâÊï∞ÊçÆÈúÄË¶Å‰øùÂ≠òÂà∞ Excel")
                return
            
            print(f"\nüìä ÁîüÊàê Excel Êñá‰ª∂...")
            
            for site_name, rows in self.excel_data.items():
                if not rows:
                    continue
                
                # ÂàõÂª∫Â∑•‰ΩúÁ∞ø
                wb = Workbook()
                ws = wb.active
                ws.title = "Á¥†ÊùêÊï∞ÊçÆ"
                
                # ËÆæÁΩÆË°®Â§¥
                headers = ["‰ΩúÂìÅURL", "ÂéüÂõæURL", "ÊèêÁ§∫ËØç", "Áº©Áï•ÂõæURL"]
                ws.append(headers)
                
                # ËÆæÁΩÆË°®Â§¥Ê†∑Âºè
                for cell in ws[1]:
                    cell.font = Font(bold=True, size=12)
                    cell.alignment = Alignment(horizontal='center', vertical='center')
                
                # Ê∑ªÂä†Êï∞ÊçÆ
                print(f"  üìù ÂºÄÂßãÂÜôÂÖ• {len(rows)} Ë°åÊï∞ÊçÆÂà∞Excel...")
                for row_idx, row in enumerate(rows, start=1):
                    # Ê£ÄÊü•ÊèêÁ§∫ËØçÂàóÔºàÁ¨¨3ÂàóÔºâ
                    if len(row) >= 3:
                        prompt = row[2]
                        if row_idx <= 3:  # Âè™ÊâìÂç∞Ââç3Ë°å
                            print(f"    Ë°å{row_idx} - ÊèêÁ§∫ËØçÈïøÂ∫¶: {len(str(prompt))} Â≠óÁ¨¶")
                            print(f"           Ââç50Â≠óÁ¨¶: {str(prompt)[:50]}")
                    ws.append(row)
                
                # ËÆæÁΩÆÂçïÂÖÉÊ†ºÊ†∑ÂºèÔºöÊñáÊú¨Êç¢Ë°å + ‰º∞ÁÆóË°åÈ´ò
                for row_idx, row_cells in enumerate(ws.iter_rows(min_row=2), start=2):
                    max_text_length = 0
                    for cell_idx, cell in enumerate(row_cells):
                        cell.alignment = Alignment(wrap_text=True, vertical='top')
                        # Ê£ÄÊü•Á¨¨3ÂàóÔºàÊèêÁ§∫ËØçÔºâÁöÑÊñáÊú¨ÈïøÂ∫¶
                        if cell_idx == 2 and cell.value:  # Á¨¨3ÂàóÊòØÊèêÁ§∫ËØç
                            text_length = len(str(cell.value))
                            max_text_length = max(max_text_length, text_length)
                    
                    # Ê†πÊçÆÊèêÁ§∫ËØçÈïøÂ∫¶ËÆæÁΩÆË°åÈ´ò
                    if max_text_length > 80:
                        # ‰º∞ÁÆóË°åÈ´òÔºöÊØè80Â≠óÁ¨¶‰∏ÄË°åÔºåÊØèË°å15Á£Ö
                        estimated_lines = (max_text_length // 80) + 1
                        ws.row_dimensions[row_idx].height = min(estimated_lines * 15, 300)  # ÊúÄÈ´ò300Á£Ö
                    else:
                        ws.row_dimensions[row_idx].height = 30  # ÈªòËÆ§Ë°åÈ´ò
                
                # Ëá™Âä®Ë∞ÉÊï¥ÂàóÂÆΩÔºàÊèêÁ§∫ËØçÂàóÁâπÊÆäÂ§ÑÁêÜÔºâ
                for col_idx, column in enumerate(ws.columns, start=1):
                    max_length = 0
                    column_letter = column[0].column_letter
                    
                    # Á¨¨3ÂàóÊòØÊèêÁ§∫ËØçÔºåËÆæÁΩÆÂõ∫ÂÆöÂÆΩÂ∫¶80
                    if col_idx == 3:
                        ws.column_dimensions[column_letter].width = 80
                    else:
                        for cell in column:
                            try:
                                if len(str(cell.value)) > max_length:
                                    max_length = len(str(cell.value))
                            except:
                                pass
                        adjusted_width = min(max_length + 2, 100)
                        ws.column_dimensions[column_letter].width = adjusted_width
                
                # ‰øùÂ≠òÊñá‰ª∂
                excel_path = self.output_dir.parent / f'{site_name}.xlsx'
                wb.save(excel_path)
                print(f"  ‚úÖ {site_name}.xlsx ({len(rows)} Êù°)")
                
                # „ÄêÈ™åËØÅ„ÄëËØªÂèñ‰øùÂ≠òÁöÑÊñá‰ª∂ÔºåÊ£ÄÊü•ÊèêÁ§∫ËØçÊòØÂê¶ÂÆåÊï¥
                print(f"  üîç È™åËØÅExcelÊñá‰ª∂...")
                wb_check = load_workbook(excel_path)
                ws_check = wb_check.active
                for row_idx in range(2, min(4, ws_check.max_row + 1)):  # Ê£ÄÊü•Ââç2Ë°åÊï∞ÊçÆ
                    cell_value = ws_check.cell(row_idx, 3).value  # Á¨¨3ÂàóÊòØÊèêÁ§∫ËØç
                    if cell_value:
                        print(f"    Ë°å{row_idx-1} ÊèêÁ§∫ËØçÈïøÂ∫¶: {len(str(cell_value))} Â≠óÁ¨¶")
                        print(f"           ÂÜÖÂÆπ: {str(cell_value)[:100]}...")
                wb_check.close()
            
            print(f"üìä Excel Êñá‰ª∂ÁîüÊàêÂÆåÊàêÔºÅ")
            
        except Exception as e:
            print(f"  ‚ö†Ô∏è  ÁîüÊàê Excel Â§±Ë¥•: {e}")
            import traceback
            traceback.print_exc()
    
    
    def get_summary(self) -> Dict:
        """Ëé∑ÂèñÊï∞ÊçÆÊëòË¶ÅÔºàÂü∫‰∫é Excel Êï∞ÊçÆÔºâ"""
        total_count = sum(len(rows) for rows in self.excel_data.values() if rows)
        # ÂáèÂéªÈáçÂ§çÁöÑ all_materials ËÆ°Êï∞
        if 'all_materials' in self.excel_data:
            total_count = len(self.excel_data['all_materials'])
        
        return {
            'text2video_count': 0,  # Â∑≤‰∏çÂÜçÂçïÁã¨ÁªüËÆ°
            'image2video_count': 0,  # Â∑≤‰∏çÂÜçÂçïÁã¨ÁªüËÆ°
            'total_count': total_count
        }


def setup_proxy(proxy_config: Dict) -> Optional[Dict]:
    """
    ËÆæÁΩÆ‰ª£ÁêÜ
    
    Args:
        proxy_config: ‰ª£ÁêÜÈÖçÁΩÆ
        
    Returns:
        requests‰ª£ÁêÜÂ≠óÂÖ∏
    """
    if not proxy_config.get('host'):
        return None
    
    if proxy_config.get('user') and proxy_config.get('password'):
        proxy_url = f"http://{proxy_config['user']}:{proxy_config['password']}@{proxy_config['host']}"
        if proxy_config.get('port'):
            proxy_url += f":{proxy_config['port']}"
    else:
        proxy_url = f"http://{proxy_config['host']}"
        if proxy_config.get('port'):
            proxy_url += f":{proxy_config['port']}"
    
    return {
        'http': proxy_url,
        'https': proxy_url
    }

